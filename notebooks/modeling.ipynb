{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\")))\n",
    "\n",
    "from data_loader import load_data\n",
    "\n",
    "train_data = load_data(\"train.csv\")\n",
    "test_data = load_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data['review']\n",
    "y = train_data['sentiment']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Names: ['00' '000' '10' ... 'zombie' 'zombies' 'zone']\n",
      "Train Data Shape: (32000, 5000)\n",
      "Validation Data Shape: (8000, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "\n",
    "print(\"TF-IDF Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(\"Train Data Shape:\", X_train_tfidf.shape)\n",
    "print(\"Validation Data Shape:\", X_val_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will train and compare 3 different models:\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "* Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8888\n",
      "Random Forest Accuracy: 0.8427\n",
      "SVM Accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "log_reg_preds = log_reg.predict(X_val_tfidf)\n",
    "log_reg_acc = accuracy_score(y_val, log_reg_preds)\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_acc:.4f}\")\n",
    "\n",
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "rf_preds = rf.predict(X_val_tfidf)\n",
    "rf_acc = accuracy_score(y_val, rf_preds)\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.4f}\")\n",
    "\n",
    "# Support Vector Machine Model\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "svm_preds = svm.predict(X_val_tfidf)\n",
    "svm_acc = accuracy_score(y_val, svm_preds)\n",
    "print(f\"SVM Accuracy: {svm_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not get the minimum requested accuracy from Random Forest. I am going to use Grid Search and find out the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Optimized Random Forest Accuracy: 0.8601\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "rf_preds = best_rf.predict(X_val_tfidf)\n",
    "\n",
    "rf_best_acc = accuracy_score(y_val, rf_preds)\n",
    "print(f\"Optimized Random Forest Accuracy: {rf_best_acc:.4f}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Random Forest Accuracy: 0.8601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_optimized = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    max_features='log2',\n",
    "    min_samples_split=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_optimized.fit(X_train_tfidf, y_train)\n",
    "\n",
    "rf_optimized_preds = rf_optimized.predict(X_val_tfidf)\n",
    "\n",
    "rf_optimized_acc = accuracy_score(y_val, rf_optimized_preds)\n",
    "print(f\"Optimized Random Forest Accuracy: {rf_optimized_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to results, the best model: SVM (with 0.8900 accuracy). So we can choose the SVM model as the final model.<br>\n",
    "Let's load the test data and make a prediction using our final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SVM model saved at: c:\\Users\\Serhet\\Desktop\\data-science-task\\notebooks\\..\\outputs\\models\\final_svm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_path = os.path.join(os.getcwd(), \"..\", \"outputs\", \"models\", \"final_svm_model.pkl\")\n",
    "\n",
    "joblib.dump(svm, model_path)\n",
    "print(f\"Final SVM model saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved at: c:\\Users\\Serhet\\Desktop\\data-science-task\\notebooks\\..\\outputs\\predictions\\svm_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data['review']\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "test_preds = svm.predict(X_test_tfidf)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'review': X_test,\n",
    "    'predicted_sentiment': test_preds\n",
    "})\n",
    "\n",
    "submission_path = os.path.join(os.getcwd(), \"..\", \"outputs\", \"predictions\", \"svm_test_predictions.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Predictions saved at: {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
